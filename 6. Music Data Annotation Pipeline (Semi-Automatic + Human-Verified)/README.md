-Semi-Automatic Music Data Annotation


Python-based extraction of BPM, key, MFCCs and metadata, combined with human verification and correction (human-in-the-loop).

-Overview :
This folder contains the work completed during Week 6 of AI Music Prompt Engineer / Data Curator program.
The focus is on building a lightweight pipeline for automatic and semi-automatic music data labeling, combining Python analysis tools with manual annotation guidelines.

-Objectives :
Develop Python scripts for automatic BPM estimation and key estimation from audio (librosa), and key/instrument extraction from MIDI (music21).
Compare automatic vs. manual labels to evaluate accuracy.
Explore small real-world music datasets (e.g., MAESTRO) to test the labeling pipeline.
Create a concise English guide explaining how manual + automatic annotation workflows can be used in professional data-curation roles.
Deliver clean, well-structured CSV metadata files aligned with industry standards.
-Tools & Libraries :
Python 3.13.3
librosa – audio feature extraction
music21 – symbolic music analysis (MIDI/key)
[numpy, pandas] – numerical & tabular processing
[soundfile] – audio file I/O
Small dataset (3 MAESTRO tracks) for evaluation
-Notes :
All code and data are intended for research and training purposes.
The structure and documentation mirror real Music AI Data Annotation workflows used in current industry roles.

